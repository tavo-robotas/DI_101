{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce55658-5baa-42c5-9d8b-1f71da6c3b71",
   "metadata": {},
   "source": [
    "# VGG-16 ir CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988924f7-975a-4200-856c-e1a2fe1748fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106391e-371f-4a93-824e-86f1ce149c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_evaluation import set_all_seeds, set_deterministic, compute_confusion_matrix\n",
    "from helper_train_extended import train_model\n",
    "from helper_plotting_extended import plot_training_loss, plot_accuracy, show_examples, plot_confusion_matrix\n",
    "from helper_dataset_extended import get_dataloaders_cifar10, UnNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347bd9d-979e-4986-b0da-820d467472ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d6de2-9026-4218-9340-d370f493a983",
   "metadata": {},
   "source": [
    "## Duomenys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc8273-f992-4b35-8686-3c69d8f558cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),\n",
    "    torchvision.transforms.RandomCrop((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),        \n",
    "    torchvision.transforms.CenterCrop((64, 64)),            \n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_cifar10(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_fraction=0.1,\n",
    "    train_transforms=train_transforms,\n",
    "    test_transforms=test_transforms,\n",
    "    num_workers=2)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91496e0-c400-4799-9e3b-046a7a6fb64e",
   "metadata": {},
   "source": [
    "## Modelis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3f312-1f16-4302-ada8-86b5bf8f48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block_1 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=3,\n",
    "                                out_channels=64,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=64,\n",
    "                                out_channels=64,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_2 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=64,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=128,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_3 = torch.nn.Sequential(        \n",
    "                torch.nn.Conv2d(in_channels=128,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "          \n",
    "        self.block_4 = torch.nn.Sequential(   \n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_5 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),    \n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))             \n",
    "        )\n",
    "        \n",
    "        # galbūt norėsite tai pakeisti, atsižvelgdami į įvesties dydį  \n",
    "        height, width = 3, 3 \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512*height*width, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, num_classes),\n",
    "        )\n",
    "            \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.torch.nn.Conv2d) or isinstance(m, torch.torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "                    \n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((height, width))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        logits = self.classifier(x)\n",
    "        #probas = F.softmax(logits, dim=1)\n",
    "\n",
    "        return logits                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af699a5d-1325-40a6-b89e-121601a9bda9",
   "metadata": {},
   "source": [
    "## Treniravimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4079982-4cef-4ccb-95d9-4f793fc95da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(num_classes=10)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_on='valid_acc',\n",
    "    logging_interval=100)\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=200)\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)\n",
    "plt.ylim([60, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c6ff7f-50af-4cd3-bd6e-5d21f317e380",
   "metadata": {},
   "source": [
    "## Testavimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154f08e-0409-48e1-be5e-6441c35490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "unnormalizer = UnNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "class_dict = {0: 'airplane',\n",
    "              1: 'automobile',\n",
    "              2: 'bird',\n",
    "              3: 'cat',\n",
    "              4: 'deer',\n",
    "              5: 'dog',\n",
    "              6: 'frog',\n",
    "              7: 'horse',\n",
    "              8: 'ship',\n",
    "              9: 'truck'}\n",
    "\n",
    "show_examples(model=model, data_loader=test_loader, unnormalizer=unnormalizer, class_dict=class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124823c9-70d1-4bda-9bb4-f06a7ad82e63",
   "metadata": {},
   "source": [
    "## Rezultatai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51b626-f60a-4208-9eed-f793d53df291",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = compute_confusion_matrix(model=model, data_loader=test_loader, device=torch.device('cpu'))\n",
    "plot_confusion_matrix(mat, class_names=class_dict.values())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
