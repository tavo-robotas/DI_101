{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a4f2e-7196-4e1b-b389-ec84db37c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7837a6-f535-4cf3-96c4-873a870b86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_evaluation import set_all_seeds, set_deterministic, compute_confusion_matrix\n",
    "from helper_train import train_model\n",
    "from helper_plotting import plot_training_loss, plot_accuracy, show_examples, plot_confusion_matrix\n",
    "from helper_dataset import get_dataloaders_cifar10, UnNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc7cdb-e3f6-4c37-b1c3-a7ba022c5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d26b56-c790-4aa4-a5af-e97b8b56e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),\n",
    "    torchvision.transforms.RandomCrop((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                      ])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),        \n",
    "    torchvision.transforms.CenterCrop((64, 64)),            \n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_cifar10(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_fraction=0.1,\n",
    "    train_transforms=train_transforms,\n",
    "    test_transforms=test_transforms,\n",
    "    num_workers=2)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82b1b5-4764-433f-aac7-d3b06e30d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = torch.nn.Sequential(\n",
    "                      torch.nn.Conv2d(in_channels=3,\n",
    "                                      out_channels=16,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1,\n",
    "                                      bias=False),\n",
    "                      torch.nn.BatchNorm2d(16),\n",
    "                      torch.nn.ReLU(inplace=True),\n",
    "                      torch.nn.Conv2d(in_channels=16,\n",
    "                                      out_channels=16,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1,\n",
    "                                      bias=False),   \n",
    "                      torch.nn.BatchNorm2d(16),\n",
    "                      torch.nn.ReLU(inplace=True),\n",
    "                      torch.nn.Conv2d(in_channels=16,\n",
    "                                      out_channels=32,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1,\n",
    "                                      bias=False),        \n",
    "                      torch.nn.BatchNorm2d(32),\n",
    "                      torch.nn.ReLU(inplace=True),                        \n",
    "                      torch.nn.Conv2d(in_channels=32,\n",
    "                                      out_channels=32,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1,\n",
    "                                      bias=False),      \n",
    "                      torch.nn.BatchNorm2d(32),\n",
    "                      torch.nn.ReLU(inplace=True),       \n",
    "                      torch.nn.Conv2d(in_channels=32,\n",
    "                                      out_channels=64,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1,\n",
    "                                      bias=False),   \n",
    "                      torch.nn.BatchNorm2d(64),\n",
    "                      torch.nn.ReLU(inplace=True),\n",
    "                      torch.nn.Conv2d(in_channels=64,\n",
    "                                      out_channels=64,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1,\n",
    "                                      bias=False),     \n",
    "                      torch.nn.BatchNorm2d(64),\n",
    "                      torch.nn.ReLU(inplace=True),\n",
    "                      torch.nn.Conv2d(in_channels=64,\n",
    "                                      out_channels=num_classes,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1,\n",
    "                                      bias=False),    \n",
    "                      torch.nn.BatchNorm2d(10),\n",
    "                      torch.nn.ReLU(inplace=True),\n",
    "                      torch.nn.AdaptiveAvgPool2d(1),\n",
    "                      torch.nn.Flatten()\n",
    "    )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.net(x)\n",
    "        #probas = torch.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bc2db-7a50-4d19-84b8-abad3fdc18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AllConvNet(num_classes=10)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_on='valid_acc',\n",
    "    logging_interval=100)\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=200)\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)\n",
    "plt.ylim([60, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4aa4a-3e95-4441-9a0f-806877d2cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "unnormalizer = UnNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "class_dict = {0: 'airplane',\n",
    "              1: 'automobile',\n",
    "              2: 'bird',\n",
    "              3: 'cat',\n",
    "              4: 'deer',\n",
    "              5: 'dog',\n",
    "              6: 'frog',\n",
    "              7: 'horse',\n",
    "              8: 'ship',\n",
    "              9: 'truck'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c4a8a-6376-41d5-8d6b-55a1958c8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = compute_confusion_matrix(model=model, data_loader=test_loader, device=torch.device('cpu'))\n",
    "plot_confusion_matrix(mat, class_names=class_dict.values())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
